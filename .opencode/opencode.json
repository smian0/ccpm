{
  "$schema": "https://opencode.ai/config.json",
  "theme": "opencode",
  "model": "ollamat/gpt-oss:120b",
  "autoupdate": true,
  "provider": {
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama (local)",
      "options": {
        "baseURL": "http://localhost:3304/v1"
      },
      "models": {
        "gpt-oss:20b": {
          "name": "GPT-OSS 20B (Local)"
        },
        "gpt-oss:120b": {
          "name": "GPT-OSS 120B (Local)"
        },
        "deepseek-v3.1:671b": {
          "name": "DeepSeek V3.1 671B (Local)"
        }
      }
    },
    "ollamat": {
      "npm": "ollama-ai-provider-v2",
      "name": "Ollama (turbo)",
      "options": {
        "baseURL": "https://ollama.com/api",
        "headers": {
          "Authorization": "Bearer {env:OLLAMA_API_KEY}"
        }
      },
      "models": {
        "gpt-oss:20b": {
          "name": "GPT-OSS 20B (Turbo)"
        },
        "gpt-oss:120b": {
          "name": "GPT-OSS 120B (Turbo)"
        },
        "deepseek-v3.1:671b": {
          "name": "DeepSeek V3.1 671B (Turbo)"
        }
      }
    },
    "zhipuai": {
      "api": "https://api.z.ai/api/coding/paas/v4"
    }
  },
  "mcp": {
    "markdown": {
      "type": "local",
      "command": ["uv", "run", "/Users/smian/dotfiles/claude/.claude/mcp_servers/mcp_markdown/server.py"],
      "enabled": true
    },
    "streamable-mcp-server": {
      "type": "remote",
      "url": "http://127.0.0.1:12306/mcp",
      "enabled": false
    }
  },
  "tools": {
    "mcp__markdown__*": true
  },
  "permission": {
    "edit": "allow",
    "bash": "allow", 
    "webfetch": "allow"
  },
  "agent": {
    "plan": {
      "model": "ollamat/gpt-oss:120b"
    },
    "build": {
      "model": "ollamat/gpt-oss:120b"
    },
    "general": {
      "model": "ollamat/gpt-oss:120b"
    },
     "reasoning": {
       "model": "ollamat/gpt-oss:120b",
       "system": "You are a highâ€‘quality reasoning assistant. Always provide step-by-step <reasoning></reasoning> tags before the final answer.",
       "reasoningEffort": "medium"
     },
     "websearch": {
       "model": "ollamat/gpt-oss:120b",
       "system": "You are a concise web-search assistant. Retrieve the most relevant information for the given query and return a short factual summary (max 3 sentences). Cite the source URL at the end.",
       "reasoningEffort": "medium"
     },
     "markdown-pro": {
       "model": "ollamat/gpt-oss:120b",
       "temperature": 0.1,
       "system": "You are a markdown specialist. Help with markdown formatting, structure, and best practices.",
       "tools": {
         "mcp__markdown__*": true
       }
     },
     "news": {
       "model": "ollamat/gpt-oss:120b",
       "system": "You are a news analyst. Provide concise, factual summaries of current events and news topics."
     },
     "file-analyzer": {
       "model": "ollamat/gpt-oss:120b",
       "temperature": 0.1,
       "system": "You are a file content analyst. Read and summarize verbose files, logs, and documents. Extract key insights while dramatically reducing context usage."
     },
     "test-runner": {
       "model": "ollamat/gpt-oss:120b", 
       "temperature": 0.1,
       "system": "You are a test execution specialist. Run tests, capture comprehensive logs, and analyze failures. Provide actionable insights while preserving main conversation context."
     },
     "parallel-worker": {
       "model": "ollamat/gpt-oss:120b",
       "temperature": 0.1,
       "system": "You are a parallel execution coordinator. Manage multiple work streams, spawn sub-agents, and consolidate results for git worktree-based parallel development."
     },
     "code-analyzer": {
       "model": "ollamat/gpt-oss:120b",
       "temperature": 0.1,
       "system": "You are an elite bug hunting specialist with deep expertise in code analysis, logic tracing, and vulnerability detection. Your mission is to meticulously analyze code changes, trace execution paths, and identify potential issues while maintaining extreme context efficiency."
     },
     "zai-test": {
       "model": "zhipuai/glm-4.5",
       "temperature": 0.1,
       "system": "You are a helpful AI assistant powered by GLM-4.5."
     }
  }
}